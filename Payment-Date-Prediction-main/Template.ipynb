{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1beb9ef3",
   "metadata": {
    "id": "wcq6dWzy1ZR0"
   },
   "source": [
    "# Payment Date Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9bdc2",
   "metadata": {
    "id": "2778654e"
   },
   "source": [
    "\n",
    "### Importing related Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8eaf61c",
   "metadata": {
    "id": "304c9e38"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27c2a18",
   "metadata": {
    "id": "8724f5ee"
   },
   "source": [
    "### Store the dataset into the Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ea02d",
   "metadata": {
    "id": "415db50a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63b7d89c",
   "metadata": {
    "id": "42e37f05"
   },
   "source": [
    "### Check the shape of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db4d38",
   "metadata": {
    "id": "27cc0907"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "497fe247",
   "metadata": {
    "id": "b68c955d"
   },
   "source": [
    "### Check the Detail information of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaaba01",
   "metadata": {
    "id": "e092ec9e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af123581",
   "metadata": {
    "id": "112f2d0e"
   },
   "source": [
    "### Display All the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed3539",
   "metadata": {
    "id": "1416e2fd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a447fde",
   "metadata": {
    "id": "d465ed7a"
   },
   "source": [
    "### Describe the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ce3e2",
   "metadata": {
    "id": "25f65e1b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0fbc757",
   "metadata": {
    "id": "0f2c8d02"
   },
   "source": [
    "# Data Cleaning\n",
    "\n",
    "- Show top 5 records from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b325cb",
   "metadata": {
    "id": "8f876212"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b07cd4d",
   "metadata": {
    "id": "92b044e4"
   },
   "source": [
    "### Display the Null values percentage against every columns (compare to the total number of records)\n",
    "\n",
    "- Output expected : area_business - 100% null, clear_data = 20% null, invoice_id = 0.12% null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb50b3f",
   "metadata": {
    "id": "24c7b13d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70083f84",
   "metadata": {
    "id": "2c46a98b"
   },
   "source": [
    "### Display Invoice_id and Doc_Id\n",
    "\n",
    "- Note - Many of the would have same invoice_id and doc_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9d062",
   "metadata": {
    "id": "038f24bb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61e7521d",
   "metadata": {
    "id": "18cfe10a"
   },
   "source": [
    "#### Write a code to check - 'baseline_create_date',\"document_create_date\",'document_create_date.1' - these columns are almost same.\n",
    "\n",
    "- Please note, if they are same, we need to drop them later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b495253",
   "metadata": {
    "id": "cf5b40ff"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef09af0c",
   "metadata": {
    "id": "33110576"
   },
   "source": [
    "#### Please check, Column 'posting_id' is constant columns or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341b3a2",
   "metadata": {
    "id": "ecce2664"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867b1f97",
   "metadata": {
    "id": "e5fb8daf"
   },
   "source": [
    "#### Please check 'isOpen' is a constant column and relevant column for this project or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ebc1b4",
   "metadata": {
    "id": "8db9956b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ed6dec2",
   "metadata": {
    "id": "45a11a62"
   },
   "source": [
    "### Write the code to drop all the following columns from the dataframe\n",
    "\n",
    "- 'area_business'\n",
    "- \"posting_id\"\n",
    "- \"invoice_id\"\n",
    "- \"document_create_date\"\n",
    "- \"isOpen\"\n",
    "- 'document type' \n",
    "- 'document_create_date.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc082128",
   "metadata": {
    "id": "270d85d1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbb03c8b",
   "metadata": {
    "id": "K5LHAM2XVGnk"
   },
   "source": [
    "### Please check from the dataframe whether all the columns are removed or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba9495",
   "metadata": {
    "id": "ef3f7d2b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e60d9ac0",
   "metadata": {
    "id": "6bc052c7"
   },
   "source": [
    "### Show all the Duplicate rows from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2587b",
   "metadata": {
    "id": "1ae3c7e4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2c3bddd",
   "metadata": {
    "id": "464fab09"
   },
   "source": [
    "### Display the Number of Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b68885",
   "metadata": {
    "id": "b1ea2397"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25495da1",
   "metadata": {
    "id": "827a6718"
   },
   "source": [
    "### Drop all the Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966cccf6",
   "metadata": {
    "id": "5d10151c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d96b071",
   "metadata": {
    "id": "7e5d1f9b"
   },
   "source": [
    "#### Now check for all duplicate rows now\n",
    "\n",
    "- Note - It must be 0 by now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ef547",
   "metadata": {
    "id": "9accc9fc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca3407bd",
   "metadata": {
    "id": "d0704898"
   },
   "source": [
    "### Check for the number of Rows and Columns in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9e68c",
   "metadata": {
    "id": "582748a8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aefab757",
   "metadata": {
    "id": "4o9c5UodWRtl"
   },
   "source": [
    "### Find out the total count of null values in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e443afb",
   "metadata": {
    "id": "b0612cb5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f358317",
   "metadata": {
    "id": "7abdb98b"
   },
   "source": [
    "#Data type Conversion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15302d59",
   "metadata": {
    "id": "LPfSUSp-WpPj"
   },
   "source": [
    "### Please check the data type of each column of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f836e29",
   "metadata": {
    "id": "689c8592"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b1692a2",
   "metadata": {
    "id": "0nsem0_3XzOt"
   },
   "source": [
    "### Check the datatype format of below columns\n",
    "\n",
    "- clear_date  \n",
    "- posting_date\n",
    "- due_in_date \n",
    "- baseline_create_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fadf7f",
   "metadata": {
    "id": "-yyODyW3X6pL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9f1848e",
   "metadata": {
    "id": "11cf9478"
   },
   "source": [
    "### converting date columns into date time formats\n",
    "\n",
    "- clear_date  \n",
    "- posting_date\n",
    "- due_in_date \n",
    "- baseline_create_date\n",
    "\n",
    "\n",
    "- **Note - You have to convert all these above columns into \"%Y%m%d\" format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf5350b",
   "metadata": {
    "id": "9a8c6c71"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91eeaf8f",
   "metadata": {
    "id": "7adq0wSIYSCS"
   },
   "source": [
    "### Please check the datatype of all the columns after conversion of the above 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc7b3bc",
   "metadata": {
    "id": "fd028c61"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c78e2247",
   "metadata": {
    "id": "8c9882fa"
   },
   "source": [
    "#### the invoice_currency column contains two different categories, USD and CAD\n",
    "\n",
    "- Please do a count of each currency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b87f5",
   "metadata": {
    "id": "72085397"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f4265e5",
   "metadata": {
    "id": "6cbe26ee"
   },
   "source": [
    "#### display the \"total_open_amount\" column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6bb4b",
   "metadata": {
    "id": "6c49f2ab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ec51a9b",
   "metadata": {
    "id": "df899966"
   },
   "source": [
    "### Convert all CAD into USD currency of \"total_open_amount\" column\n",
    "\n",
    "- 1 CAD = 0.7 USD\n",
    "- Create a new column i.e \"converted_usd\" and store USD and convered CAD to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671caf3",
   "metadata": {
    "id": "8eb2f1c5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b008ab3",
   "metadata": {
    "id": "f9f6ef1d"
   },
   "source": [
    "### Display the new \"converted_usd\" column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b4e45",
   "metadata": {
    "id": "1fc1a178"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e69c3977",
   "metadata": {
    "id": "6XLXX17kayuy"
   },
   "source": [
    "### Display year wise total number of record \n",
    "\n",
    "- Note -  use \"buisness_year\" column for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7b110",
   "metadata": {
    "id": "00c9f6ee"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "017779d4",
   "metadata": {
    "id": "05c35904"
   },
   "source": [
    "### Write the code to delete the following columns \n",
    "\n",
    "- 'invoice_currency'\n",
    "- 'total_open_amount', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda4153",
   "metadata": {
    "id": "4ac28aa5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d4bd50a",
   "metadata": {
    "id": "bDBJ_Kvwc086"
   },
   "source": [
    "### Write a code to check the number of columns in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6e695",
   "metadata": {
    "id": "ea360a8c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc387123",
   "metadata": {
    "id": "b8f63655"
   },
   "source": [
    "# Splitting the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad322f8b",
   "metadata": {
    "id": "a00f749d"
   },
   "source": [
    "### Look for all columns containing null value\n",
    "\n",
    "- Note - Output expected is only one column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd76249",
   "metadata": {
    "id": "148c801e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4781d644",
   "metadata": {
    "id": "a094a290"
   },
   "source": [
    "#### Find out the number of null values from the column that you got from the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9e4f4",
   "metadata": {
    "id": "30bfb113"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a4c6ed",
   "metadata": {
    "id": "7f6d939b"
   },
   "source": [
    "### On basis of the above column we are spliting data into dataset\n",
    "\n",
    "- First dataframe (refer that as maindata) only containing the rows, that have NO NULL data in that column ( This is going to be our train dataset ) \n",
    "- Second dataframe (refer that as nulldata) that contains the columns, that have Null data in that column ( This is going to be our test dataset ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be2d0e3",
   "metadata": {
    "id": "c8764c33"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10c0f0af",
   "metadata": {
    "id": "3P8riRBHd_r6"
   },
   "source": [
    "### Check the number of Rows and Columns for both the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20cc42",
   "metadata": {
    "id": "0693a464"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29dee65",
   "metadata": {
    "id": "7f86bc74"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3c581b2",
   "metadata": {
    "id": "0747165d"
   },
   "source": [
    "### Display the 5 records from maindata and nulldata dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d822106",
   "metadata": {
    "id": "dec2ec36"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ab5af",
   "metadata": {
    "id": "eee2d68a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a6b47b5",
   "metadata": {
    "id": "24aa6746"
   },
   "source": [
    "## Considering the **maindata**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90384fd8",
   "metadata": {
    "id": "f92c4aa7"
   },
   "source": [
    "#### Generate a new column \"Delay\" from the existing columns\n",
    "\n",
    "- Note - You are expected to create a new column 'Delay' from two existing columns, \"clear_date\" and \"due_in_date\" \n",
    "- Formula - Delay = clear_date - due_in_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c9f2df",
   "metadata": {
    "id": "8eeceb9c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7fcb2a6",
   "metadata": {
    "id": "f482144e"
   },
   "source": [
    "### Generate a new column \"avgdelay\" from the existing columns\n",
    "\n",
    "- Note - You are expected to make a new column \"avgdelay\" by grouping \"name_customer\" column with reapect to mean of the \"Delay\" column.\n",
    "- This new column \"avg_delay\" is meant to store \"customer_name\" wise delay\n",
    "- groupby('name_customer')['Delay'].mean(numeric_only=False)\n",
    "- Display the new \"avg_delay\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd03b0",
   "metadata": {
    "id": "d18d2f8d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1b08ea7",
   "metadata": {
    "id": "64b995e8"
   },
   "source": [
    "You need to add the \"avg_delay\" column with the maindata, mapped with \"name_customer\" column\n",
    "\n",
    " - Note - You need to use map function to map the avgdelay with respect to \"name_customer\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a643d",
   "metadata": {
    "id": "e1e1f3d9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42e1e1d4",
   "metadata": {
    "id": "1d332525"
   },
   "source": [
    "### Observe that the \"avg_delay\" column is in days format. You need to change the format into seconds\n",
    "\n",
    "- Days_format :  17 days 00:00:00\n",
    "- Format in seconds : 1641600.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612f4e4",
   "metadata": {
    "id": "d5f1041e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "931d20fe",
   "metadata": {
    "id": "OvgtHSsx_O-n"
   },
   "source": [
    "### Display the maindata dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8b762",
   "metadata": {
    "id": "97ca9c45"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5388db08",
   "metadata": {
    "id": "ae24c7bb"
   },
   "source": [
    "### Since you have created the \"avg_delay\" column from \"Delay\" and \"clear_date\" column, there is no need of these two columns anymore \n",
    "\n",
    "- You are expected to drop \"Delay\" and \"clear_date\" columns from maindata dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87890609",
   "metadata": {
    "id": "78a61ab9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "746f700b",
   "metadata": {
    "id": "ae724bfc"
   },
   "source": [
    "# Splitting of Train and the Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55628d77",
   "metadata": {
    "id": "cb6f0264"
   },
   "source": [
    "### You need to split the \"maindata\" columns into X and y dataframe\n",
    "\n",
    "- Note - y should have the target column i.e. \"avg_delay\" and the other column should be in X\n",
    "\n",
    "- X is going to hold the source fields and y will be going to hold the target fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d181942",
   "metadata": {
    "id": "75ab29ab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55c721",
   "metadata": {
    "id": "6412c62b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfa435e8",
   "metadata": {
    "id": "1c2942bf"
   },
   "source": [
    "#### You are expected to split both the dataframes into train and test format in 60:40 ratio \n",
    "\n",
    "- Note - The expected output should be in \"X_train\", \"X_loc_test\", \"y_train\", \"y_loc_test\" format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134eab00",
   "metadata": {
    "id": "d92160a5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c878cbe6",
   "metadata": {
    "id": "p4OME62pDufR"
   },
   "source": [
    "### Please check for the number of rows and columns of all the new dataframes (all 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6948e",
   "metadata": {
    "id": "48328d0a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9b31f5a",
   "metadata": {
    "id": "4a68ed71"
   },
   "source": [
    "### Now you are expected to split the \"X_loc_test\" and \"y_loc_test\" dataset into \"Test\" and \"Validation\" (as the names given below) dataframe with 50:50 format \n",
    "\n",
    "- Note - The expected output should be in \"X_val\", \"X_test\", \"y_val\", \"y_test\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea46dbf",
   "metadata": {
    "id": "b56c62f2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39832dfb",
   "metadata": {
    "id": "bJTSAskvERH1"
   },
   "source": [
    "### Please check for the number of rows and columns of all the 4 dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e01f55",
   "metadata": {
    "id": "845d7564"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0516b7cc",
   "metadata": {
    "id": "110fa872"
   },
   "source": [
    "# Exploratory Data Analysis (EDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a9a46",
   "metadata": {
    "id": "ffc8fe0f"
   },
   "source": [
    "### Distribution Plot of the target variable (use the dataframe which contains the target field)\n",
    "\n",
    "- Note - You are expected to make a distribution plot for the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26662ead",
   "metadata": {
    "id": "ba2bf8ed"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bed8144",
   "metadata": {
    "id": "d0e323a3"
   },
   "source": [
    "### You are expected to group the X_train dataset on 'name_customer' column with 'doc_id' in the x_train set\n",
    "\n",
    "### Need to store the outcome into a new dataframe \n",
    "\n",
    "- Note code given for groupby statement- X_train.groupby(by=['name_customer'], as_index=False)['doc_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a81ec5",
   "metadata": {
    "id": "f7acf0ee"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "444d273d",
   "metadata": {
    "id": "cA43bFffFt6i"
   },
   "source": [
    "### You can make another distribution plot of the \"doc_id\" column from x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342eec60",
   "metadata": {
    "id": "9576bf33"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "668c13c0",
   "metadata": {
    "id": "fba2c44f"
   },
   "source": [
    "#### Create a Distribution plot only for business_year and a seperate distribution plot of \"business_year\" column along with the doc_id\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1f200",
   "metadata": {
    "id": "4fecec77"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d20d9f",
   "metadata": {
    "id": "qr1jGhfOKjnw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b34ff848",
   "metadata": {
    "id": "968fbcc9"
   },
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d84f0",
   "metadata": {
    "id": "jbh6CyGqH3XE"
   },
   "source": [
    "### Display and describe the X_train dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd0ae4",
   "metadata": {
    "id": "e6bcf307"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b24a42",
   "metadata": {
    "id": "08ccc819"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed67d2d6",
   "metadata": {
    "id": "abd7ac8b"
   },
   "source": [
    "#### The \"business_code\" column inside X_train, is a categorical column, so you need to perform Labelencoder on that particular column\n",
    "\n",
    "- Note - call the Label Encoder from sklearn library and use the fit() function on \"business_code\" column\n",
    "- Note - Please fill in the blanks (two) to complete this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf14e1ea",
   "metadata": {
    "id": "7c223545"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LabelEncoder' object has no attribute '___'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25344/3313907676.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbusiness_coder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbusiness_coder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m___\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__________\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'LabelEncoder' object has no attribute '___'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "business_coder = LabelEncoder()\n",
    "business_coder.___(X_train[__________])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b4d503",
   "metadata": {
    "id": "f86f7d9c"
   },
   "source": [
    "#### You are expected to store the value into a new column i.e. \"business_code_enc\"\n",
    "\n",
    "- Note - For Training set you are expected to use fit_trainsform()\n",
    "- Note - For Test set you are expected to use the trainsform()\n",
    "- Note - For Validation set you are expected to use the trainsform()\n",
    "\n",
    "\n",
    "- Partial code is provided, please fill in the blanks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb52ac",
   "metadata": {
    "id": "4269c307"
   },
   "outputs": [],
   "source": [
    "X_train['business_code_enc'] = business_coder._____________(X_train['business_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db5ef1c",
   "metadata": {
    "id": "70a53712"
   },
   "outputs": [],
   "source": [
    "X_val['business_code_enc'] = business_coder.__________(X_val['business_code'])\n",
    "X_test['business_code_enc'] = business_coder.____________(X_test['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aeaf60",
   "metadata": {
    "id": "gdNYxTkqNfmz"
   },
   "source": [
    "### Display \"business_code\" and \"business_code_enc\" together from X_train dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ec30f",
   "metadata": {
    "id": "1196a002"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7772c20",
   "metadata": {
    "id": "11477224"
   },
   "source": [
    "#### Create a function called \"custom\" for dropping the columns 'business_code' from train, test and validation dataframe\n",
    "\n",
    "- Note - Fill in the blank to complete the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b14a5c",
   "metadata": {
    "id": "1052868a"
   },
   "outputs": [],
   "source": [
    "def ________(col ,traindf = X_train,valdf = X_val,testdf = X_test):\n",
    "    traindf.drop(col, axis =1,inplace=True)\n",
    "    valdf.drop(col,axis=1 , inplace=True)\n",
    "    testdf.drop(col,axis=1 , inplace=True)\n",
    "\n",
    "    return traindf,valdf ,testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd1c11",
   "metadata": {
    "id": "rI--ZuMbNLne"
   },
   "source": [
    "### Call the function by passing the column name which needed to be dropped from train, test and validation dataframes. Return updated dataframes to be stored in X_train ,X_val, X_test  \n",
    "\n",
    "- Note = Fill in the blank to complete the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c24956",
   "metadata": {
    "id": "1a0f955c"
   },
   "outputs": [],
   "source": [
    "________ , ______ , _______ = ______(['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df40a744",
   "metadata": {
    "id": "28b5b27e"
   },
   "source": [
    "### Manually replacing str values with numbers, Here we are trying manually replace the customer numbers with some specific values like, 'CCCA' as 1, 'CCU' as 2 and so on. Also we are converting the datatype \"cust_number\" field to int type.\n",
    "\n",
    "- We are doing it for all the three dataframes as shown below. This is fully completed code. No need to modify anything here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab932ac",
   "metadata": {
    "id": "85dd129e"
   },
   "outputs": [],
   "source": [
    "X_train['cust_number'] = X_train['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n",
    "X_test['cust_number'] = X_test['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n",
    "X_val['cust_number'] = X_val['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f233c",
   "metadata": {
    "id": "U8vA-zmdPnJ8"
   },
   "source": [
    "#### It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]. Unknown will be added in fit and transform will take care of new item. It gives unknown class id.\n",
    "\n",
    "#### This will fit the encoder for all the unique values and introduce unknown value\n",
    "\n",
    "- Note - Keep this code as it is, we will be using this later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351a1a1",
   "metadata": {
    "id": "151f48ba"
   },
   "outputs": [],
   "source": [
    "#For encoding unseen labels\n",
    "class EncoderExt(object):\n",
    "    def __init__(self):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "    def fit(self, data_list):\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "        return self\n",
    "    def transform(self, data_list):\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "        return self.label_encoder.transform(new_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b07334",
   "metadata": {
    "id": "254c64e6"
   },
   "source": [
    "### Use the user define Label Encoder function called \"EncoderExt\" for the \"name_customer\" column\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd3873",
   "metadata": {
    "id": "62b17eff"
   },
   "outputs": [],
   "source": [
    "label_encoder = EncoderExt()\n",
    "label_encoder.fit(X_train['name_customer'])\n",
    "X_train['name_customer_enc']=label_encoder.transform(X_train['name_customer'])\n",
    "X_val['name_customer_enc']=label_encoder.transform(X_val['name_customer'])\n",
    "X_test['name_customer_enc']=label_encoder.transform(X_test['name_customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf90b7",
   "metadata": {
    "id": "mK7LMoy2QZhy"
   },
   "source": [
    "### As we have created the a new column \"name_customer_enc\", so now drop \"name_customer\" column from all three dataframes\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8d2de",
   "metadata": {
    "id": "ef85f1c0"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['name_customer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d2ceb",
   "metadata": {
    "id": "3aa09d22"
   },
   "source": [
    "### Using Label Encoder for the \"cust_payment_terms\" column\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc585def",
   "metadata": {
    "id": "6f9ab642"
   },
   "outputs": [],
   "source": [
    "label_encoder1 = EncoderExt()\n",
    "label_encoder1.fit(X_train['cust_payment_terms'])\n",
    "X_train['cust_payment_terms_enc']=label_encoder1.transform(X_train['cust_payment_terms'])\n",
    "X_val['cust_payment_terms_enc']=label_encoder1.transform(X_val['cust_payment_terms'])\n",
    "X_test['cust_payment_terms_enc']=label_encoder1.transform(X_test['cust_payment_terms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a105110",
   "metadata": {
    "id": "55f9a7c2"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['cust_payment_terms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214bb445",
   "metadata": {
    "id": "0788f42b"
   },
   "source": [
    "## Check the datatype of all the columns of Train, Test and Validation dataframes realted to X\n",
    "\n",
    "- Note - You are expected yo use dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3fc392",
   "metadata": {
    "id": "bc79a316"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c123a8f",
   "metadata": {
    "id": "b33242d8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637fec9",
   "metadata": {
    "id": "6bd4da71"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8cb7f93",
   "metadata": {
    "id": "LVfvuPiWPeMB"
   },
   "source": [
    "### From the above output you can notice their are multiple date columns with datetime format\n",
    "\n",
    "### In order to pass it into our model, we need to convert it into float format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716456aa",
   "metadata": {
    "id": "9d344db9"
   },
   "source": [
    "### You need to extract day, month and year from the \"posting_date\" column \n",
    "\n",
    "1.   Extract days from \"posting_date\" column and store it into a new column \"day_of_postingdate\" for train, test and validation dataset \n",
    "2.   Extract months from \"posting_date\" column and store it into a new column \"month_of_postingdate\" for train, test and validation dataset\n",
    "3.   Extract year from \"posting_date\" column and store it into a new column \"year_of_postingdate\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02fb759",
   "metadata": {
    "id": "6e3cdfd6"
   },
   "outputs": [],
   "source": [
    "X_train['day_of_postingdate'] = X_train['posting_date'].dt.day\n",
    "X_train['month_of_postingdate'] = X_train['posting_date'].dt.month\n",
    "X_train['year_of_postingdate'] = X_train['posting_date'].dt.year\n",
    "\n",
    "X_val['day_of_postingdate'] = X_val['posting_date'].dt.day\n",
    "X_val['month_of_postingdate'] = X_val['posting_date'].dt.month\n",
    "X_val['year_of_postingdate'] = X_val['posting_date'].dt.year\n",
    "\n",
    "\n",
    "X_test['day_of_postingdate'] = X_test['posting_date'].dt.day\n",
    "X_test['month_of_postingdate'] = X_test['posting_date'].dt.month\n",
    "X_test['year_of_postingdate'] = X_test['posting_date'].dt.year\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb80474",
   "metadata": {
    "id": "GyI-F853Rxa7"
   },
   "source": [
    "### pass the \"posting_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756a6cc",
   "metadata": {
    "id": "FQHtQkrnRx_V"
   },
   "outputs": [],
   "source": [
    "X_train ,X_val, X_test = custom(['posting_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6816be73",
   "metadata": {
    "id": "GMnCaEcKReSw"
   },
   "source": [
    "### You need to extract day, month and year from the \"baseline_create_date\" column \n",
    "\n",
    "1.   Extract days from \"baseline_create_date\" column and store it into a new column \"day_of_createdate\" for train, test and validation dataset \n",
    "2.   Extract months from \"baseline_create_date\" column and store it into a new column \"month_of_createdate\" for train, test and validation dataset\n",
    "3.   Extract year from \"baseline_create_date\" column and store it into a new column \"year_of_createdate\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "\n",
    "- Note - Do as it is been shown in the previous two code boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190788e6",
   "metadata": {
    "id": "ee4d83d0"
   },
   "source": [
    "### Extracting Day, Month, Year for 'baseline_create_date' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1aeafb",
   "metadata": {
    "id": "32b240e1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9098d5a",
   "metadata": {
    "id": "cFgwkS5rSDDs"
   },
   "source": [
    "### pass the \"baseline_create_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8944a08c",
   "metadata": {
    "id": "RGYa2BEQSDg3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f27f238c",
   "metadata": {
    "id": "77c7a0df"
   },
   "source": [
    "### You need to extract day, month and year from the \"due_in_date\" column \n",
    "\n",
    "1.   Extract days from \"due_in_date\" column and store it into a new column \"day_of_due\" for train, test and validation dataset \n",
    "2.   Extract months from \"due_in_date\" column and store it into a new column \"month_of_due\" for train, test and validation dataset\n",
    "3.   Extract year from \"due_in_date\" column and store it into a new column \"year_of_due\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "- Note - Do as it is been shown in the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57953cd",
   "metadata": {
    "id": "5c745547"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "533cd6d5",
   "metadata": {
    "id": "FYLLzulGSvRd"
   },
   "source": [
    "pass the \"due_in_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea3d57",
   "metadata": {
    "id": "1-s6QuY9Svrh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4a1b171",
   "metadata": {
    "id": "1ae5d052"
   },
   "source": [
    "### Check for the datatypes for train, test and validation set again\n",
    "\n",
    "- Note - all the data type should be in either int64 or float64 format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352af574",
   "metadata": {
    "id": "aee9d828"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abea2872",
   "metadata": {
    "id": "65810f55"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07833e63",
   "metadata": {
    "id": "4bb1ad9f"
   },
   "source": [
    "### Filter Method\n",
    "\n",
    "- Calling the VarianceThreshold Function \n",
    "- Note - Keep the code as it is, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956424c",
   "metadata": {
    "id": "e882509f"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "constant_filter.fit(X_train)\n",
    "len(X_train.columns[constant_filter.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10edae74",
   "metadata": {
    "id": "V9531H3jR-W2"
   },
   "source": [
    "- Note - Keep the code as it is, no need to change \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f697e",
   "metadata": {
    "id": "c77c12e1"
   },
   "outputs": [],
   "source": [
    "constant_columns = [column for column in X_train.columns\n",
    "                    if column not in X_train.columns[constant_filter.get_support()]]\n",
    "print(len(constant_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d843195",
   "metadata": {
    "id": "6d9b8610"
   },
   "source": [
    "- transpose the feature matrice\n",
    "- print the number of duplicated features\n",
    "- select the duplicated features columns names\n",
    "\n",
    "- Note - Keep the code as it is, no need to change \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdec202",
   "metadata": {
    "id": "0fb7db95"
   },
   "outputs": [],
   "source": [
    "x_train_T = X_train.T\n",
    "print(x_train_T.duplicated().sum())\n",
    "duplicated_columns = x_train_T[x_train_T.duplicated()].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba63eb",
   "metadata": {
    "id": "510fa831"
   },
   "source": [
    "### Filtering depending upon correlation matrix value\n",
    "- We have created a function called handling correlation which is going to return fields based on the correlation matrix value with a threshold of 0.8\n",
    "\n",
    "- Note - Keep the code as it is, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92610e",
   "metadata": {
    "id": "67731abc"
   },
   "outputs": [],
   "source": [
    "def handling_correlation(X_train,threshold=0.8):\n",
    "    corr_features = set()\n",
    "    corr_matrix = X_train.corr()\n",
    "    for i in range(len(corr_matrix .columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) >threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                corr_features.add(colname)\n",
    "    return list(corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9646dbae",
   "metadata": {
    "id": "JaE_6qVgSXl3"
   },
   "source": [
    "- Note : Here we are trying to find out the relevant fields, from X_train\n",
    "- Please fill in the blanks to call handling_correlation() function with a threshold value of 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1adf6",
   "metadata": {
    "id": "dd91d1a2"
   },
   "outputs": [],
   "source": [
    "train=X_train.copy()\n",
    "____________________(train.copy(),____)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeeb58e",
   "metadata": {
    "id": "154da511"
   },
   "source": [
    "### Heatmap for X_train\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab16a6",
   "metadata": {
    "id": "2e8f2fe4"
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=20)\n",
    "sns.heatmap(X_train.merge(y_train , on = X_train.index ).corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap='gist_rainbow_r', linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d2f6c",
   "metadata": {
    "id": "e3b0d745"
   },
   "source": [
    "#### Calling variance threshold for threshold value = 0.8\n",
    "\n",
    "- Note -  Fill in the blanks to call the appropriate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160fbb7",
   "metadata": {
    "id": "a9b2080f"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = _________________(0.8)\n",
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d7aee6",
   "metadata": {
    "id": "6cb8c3dc"
   },
   "outputs": [],
   "source": [
    "sel.variances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2759cf",
   "metadata": {
    "id": "62633a84"
   },
   "source": [
    "### Features columns are \n",
    "- 'year_of_createdate' \n",
    "- 'year_of_due'\n",
    "- 'day_of_createdate'\n",
    "- 'year_of_postingdate'\n",
    "- 'month_of_due'\n",
    "- 'month_of_createdate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ae0e6",
   "metadata": {
    "id": "651f1ad0"
   },
   "source": [
    "# Modelling \n",
    "\n",
    "#### Now you need to compare with different machine learning models, and needs to find out the best predicted model\n",
    "\n",
    "- Linear Regression\n",
    "- Decision Tree Regression\n",
    "- Random Forest Regression\n",
    "- Support Vector Regression\n",
    "- Extreme Gradient Boost Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d748807",
   "metadata": {
    "id": "PicEhSuUUOkt"
   },
   "source": [
    "### You need to make different blank list for different evaluation matrix \n",
    "\n",
    "- MSE\n",
    "- R2\n",
    "- Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31596ac2",
   "metadata": {
    "id": "701e12b0"
   },
   "outputs": [],
   "source": [
    "MSE_Score = []\n",
    "R2_Score = []\n",
    "Algorithm = []\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b5b245",
   "metadata": {
    "id": "29310119"
   },
   "source": [
    "### You need to start with the baseline model Linear Regression\n",
    "\n",
    "- Step 1 : Call the Linear Regression from sklearn library\n",
    "- Step 2 : make an object of Linear Regression \n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca0d4d7",
   "metadata": {
    "id": "6bdea395"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "Algorithm.append('LinearRegression')\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafcfb17",
   "metadata": {
    "id": "G02cpnBhXJ14"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd46b0a",
   "metadata": {
    "id": "0f69ca19"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e400258",
   "metadata": {
    "id": "CsmScbHjYMv1"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5241b98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1643093994094,
     "user": {
      "displayName": "Chandramouli Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsMuDXf6PZsS77v0Q5x8metxFPnlLXsBC6Y3O7=s64",
      "userId": "13777762579346461395"
     },
     "user_tz": -330
    },
    "id": "fe653295",
    "outputId": "0c7429ca-50d0-42a2-96a1-effaa92f549e"
   },
   "outputs": [],
   "source": [
    "predict_test= regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ebe665",
   "metadata": {
    "id": "LokxV2LGYUVh"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d9e9a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1643093994095,
     "user": {
      "displayName": "Chandramouli Das",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgsMuDXf6PZsS77v0Q5x8metxFPnlLXsBC6Y3O7=s64",
      "userId": "13777762579346461395"
     },
     "user_tz": -330
    },
    "id": "9c405bd3",
    "outputId": "9d78f4a9-33fc-48d1-edc8-c997eca38de0"
   },
   "outputs": [],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a156514",
   "metadata": {
    "id": "b0e65c86"
   },
   "source": [
    "### You need to start with the baseline model Support Vector Regression\n",
    "\n",
    "- Step 1 : Call the Support Vector Regressor from sklearn library\n",
    "- Step 2 : make an object of SVR\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f22de0",
   "metadata": {
    "id": "ccb5de08"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0722ddf",
   "metadata": {
    "id": "zz9kcrViYt7e"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for \"y_test\" and \"predicted\" dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e90d72f",
   "metadata": {
    "id": "5bb9db76"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c051709f",
   "metadata": {
    "id": "0YAxd8N9Y0hJ"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51348d59",
   "metadata": {
    "id": "d6ee71b1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a64abebf",
   "metadata": {
    "id": "eGcqS5EcY4BI"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5f48c",
   "metadata": {
    "id": "aa72c1ec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e418574",
   "metadata": {
    "id": "dad18bb3"
   },
   "source": [
    "### Your next model would be Decision Tree Regression\n",
    "\n",
    "- Step 1 : Call the Decision Tree Regressor from sklearn library\n",
    "- Step 2 : make an object of Decision Tree\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd3e42",
   "metadata": {
    "id": "1b6a51eb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e586e5b0",
   "metadata": {
    "id": "AOzfgfeOZo3F"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa10ff3",
   "metadata": {
    "id": "776e6983"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a4cc61a",
   "metadata": {
    "id": "eI6d49DQZrhW"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f4f689",
   "metadata": {
    "id": "155fb55c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "992970c0",
   "metadata": {
    "id": "sbGXvBLQZw5E"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca3929",
   "metadata": {
    "id": "1d74d515"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae2c1de9",
   "metadata": {
    "id": "4ae9979b"
   },
   "source": [
    "### Your next model would be Random Forest Regression\n",
    "\n",
    "- Step 1 : Call the Random Forest Regressor from sklearn library\n",
    "- Step 2 : make an object of Random Forest\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636ea63",
   "metadata": {
    "id": "a69e476a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4773ab82",
   "metadata": {
    "id": "XNcEJF-6anof"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e0612",
   "metadata": {
    "id": "826f63f4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7085f344",
   "metadata": {
    "id": "yMbyr9V4ati1"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17effb",
   "metadata": {
    "id": "55b9fb54"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3b6dc89",
   "metadata": {
    "id": "tiBawcCsaw_Z"
   },
   "source": [
    "### Display The Comparison Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d0c6c2",
   "metadata": {
    "id": "8277c13e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "273f0920",
   "metadata": {
    "id": "e6b21881"
   },
   "source": [
    "### The last but not the least model would be XGBoost or Extreme Gradient Boost Regression\n",
    "\n",
    "- Step 1 : Call the XGBoost Regressor from xgb library\n",
    "- Step 2 : make an object of Xgboost\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose### Extreme Gradient Boost Regression\n",
    "- Note -  No need to change the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce6844",
   "metadata": {
    "id": "705a38ec"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "Algorithm.append('XGB Regressor')\n",
    "regressor = xgb.XGBRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd0cf25",
   "metadata": {
    "id": "ierNZkb9bQDD"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6e7bd",
   "metadata": {
    "id": "507a9d2f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41387b84",
   "metadata": {
    "id": "84UZ2ojsbWaH"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc4171",
   "metadata": {
    "id": "e78ac250"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4784d72",
   "metadata": {
    "id": "9FJFyaVbbbAH"
   },
   "source": [
    "### Display The Comparison Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6742f1e",
   "metadata": {
    "id": "f765ba35"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "508b9aa3",
   "metadata": {
    "id": "a71bc90f"
   },
   "source": [
    "## You need to make the comparison list into a comparison dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c5477d",
   "metadata": {
    "id": "ff5159a7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca93edb4",
   "metadata": {
    "id": "62e61c60"
   },
   "source": [
    "## Now from the Comparison table, you need to choose the best fit model\n",
    "\n",
    "- Step 1 - Fit X_train and y_train inside the model \n",
    "- Step 2 - Predict the X_test dataset\n",
    "- Step 3 - Predict the X_val dataset\n",
    "\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413bbf43",
   "metadata": {
    "id": "3e07c258"
   },
   "outputs": [],
   "source": [
    "regressorfinal = xgb.XGBRegressor()\n",
    "regressorfinal.fit(X_train, y_train)\n",
    "predictedfinal = regressorfinal.predict(X_test)\n",
    "predict_testfinal = regressorfinal.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883ca6b",
   "metadata": {
    "id": "8e4df6c4"
   },
   "source": [
    "### Calculate the Mean Square Error for test dataset\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4708643c",
   "metadata": {
    "id": "5fb466d0"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,predictedfinal,squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e886804",
   "metadata": {
    "id": "ce27f87f"
   },
   "source": [
    "### Calculate the mean Square Error for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c2520",
   "metadata": {
    "id": "b47978ea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91475c77",
   "metadata": {
    "id": "30014dbd"
   },
   "source": [
    "### Calculate the R2 score for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24950ccd",
   "metadata": {
    "id": "8a162737"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2a68360",
   "metadata": {
    "id": "1c9853b0"
   },
   "source": [
    "### Calculate the R2 score for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f887e15",
   "metadata": {
    "id": "1a6dc77c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2acaa69",
   "metadata": {
    "id": "499522d9"
   },
   "source": [
    "### Calculate the Accuracy for train Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b88ee",
   "metadata": {
    "id": "7a4f1ce8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b54190c",
   "metadata": {
    "id": "12a1c921"
   },
   "source": [
    "### Calculate the accuracy for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b91d4",
   "metadata": {
    "id": "d2579b4f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a47374a1",
   "metadata": {
    "id": "79b82e84"
   },
   "source": [
    "### Calculate the accuracy for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc93404",
   "metadata": {
    "id": "f09e6431"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d161b53",
   "metadata": {
    "id": "9488a5d9"
   },
   "source": [
    "## Specify the reason behind choosing your machine learning model \n",
    "\n",
    "- Note : Provide your answer as a text here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b956d1",
   "metadata": {
    "id": "387a6519"
   },
   "source": [
    "## Now you need to pass the Nulldata dataframe into this machine learning model\n",
    "\n",
    "#### In order to pass this Nulldata dataframe into the ML model, we need to perform the following\n",
    "\n",
    "- Step 1 : Label Encoding \n",
    "- Step 2 : Day, Month and Year extraction \n",
    "- Step 3 : Change all the column data type into int64 or float64\n",
    "- Step 4 : Need to drop the useless columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1d562",
   "metadata": {
    "id": "I7JuxAkdiAdI"
   },
   "source": [
    "### Display the Nulldata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a4131",
   "metadata": {
    "id": "6d6a51d2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9facc4b4",
   "metadata": {
    "id": "Vamx5xqtiHCH"
   },
   "source": [
    "### Check for the number of rows and columns in the nulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df60bc",
   "metadata": {
    "id": "59de1092"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22462daa",
   "metadata": {
    "id": "BxzHNbBjpqXL"
   },
   "source": [
    "### Check the Description and Information of the nulldata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00afdaa",
   "metadata": {
    "id": "a6294d29"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10fdbf51",
   "metadata": {
    "id": "fe860d94"
   },
   "source": [
    "### Storing the Nulldata into a different dataset \n",
    "# for BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a6e4c",
   "metadata": {
    "id": "16352034"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6a27196",
   "metadata": {
    "id": "00f35b8c"
   },
   "source": [
    "### Call the Label Encoder for Nulldata\n",
    "\n",
    "- Note - you are expected to fit \"business_code\" as it is a categorical variable\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34b996",
   "metadata": {
    "id": "baf04b17"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "business_codern = LabelEncoder()\n",
    "business_codern.fit(nulldata['business_code'])\n",
    "nulldata['business_code_enc'] = business_codern.transform(nulldata['business_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f29122",
   "metadata": {
    "id": "ZCPBK9karIR-"
   },
   "source": [
    "### Now you need to manually replacing str values with numbers\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228b76e",
   "metadata": {
    "id": "c64924be"
   },
   "outputs": [],
   "source": [
    "nulldata['cust_number'] = nulldata['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8760cbed",
   "metadata": {
    "id": "9a55f5f6"
   },
   "source": [
    "## You need to extract day, month and year from the \"clear_date\", \"posting_date\", \"due_in_date\", \"baseline_create_date\" columns\n",
    "\n",
    "\n",
    "##### 1.   Extract day from \"clear_date\" column and store it into 'day_of_cleardate'\n",
    "##### 2.   Extract month from \"clear_date\" column and store it into 'month_of_cleardate'\n",
    "##### 3.   Extract year from \"clear_date\" column and store it into 'year_of_cleardate'\n",
    "\n",
    "\n",
    "\n",
    "##### 4.   Extract day from \"posting_date\" column and store it into 'day_of_postingdate'\n",
    "##### 5.   Extract month from \"posting_date\" column and store it into 'month_of_postingdate'\n",
    "##### 6.   Extract year from \"posting_date\" column and store it into 'year_of_postingdate'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 7.   Extract day from \"due_in_date\" column and store it into 'day_of_due'\n",
    "##### 8.   Extract month from \"due_in_date\" column and store it into 'month_of_due'\n",
    "##### 9.   Extract year from \"due_in_date\" column and store it into 'year_of_due'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 10.   Extract day from \"baseline_create_date\" column and store it into 'day_of_createdate'\n",
    "##### 11.   Extract month from \"baseline_create_date\" column and store it into 'month_of_createdate'\n",
    "##### 12.   Extract year from \"baseline_create_date\" column and store it into 'year_of_createdate'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed To use - \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00458caf",
   "metadata": {
    "id": "4166fbe4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "450f8af0",
   "metadata": {
    "id": "QeHWJYrAvOC6"
   },
   "source": [
    "### Use Label Encoder1 of all the following columns - \n",
    "- 'cust_payment_terms' and store into 'cust_payment_terms_enc'\n",
    "- 'business_code' and store into 'business_code_enc'\n",
    "- 'name_customer' and store into 'name_customer_enc'\n",
    "\n",
    "Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba62255",
   "metadata": {
    "id": "bac330e2"
   },
   "outputs": [],
   "source": [
    "nulldata['cust_payment_terms_enc']=label_encoder1.transform(nulldata['cust_payment_terms'])\n",
    "nulldata['business_code_enc']=label_encoder1.transform(nulldata['business_code'])\n",
    "nulldata['name_customer_enc']=label_encoder.transform(nulldata['name_customer'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15acb2e1",
   "metadata": {
    "id": "zD9I-XqQwC28"
   },
   "source": [
    "### Check for the datatypes of all the columns of Nulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c45d6c",
   "metadata": {
    "id": "d4f72517"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e511d068",
   "metadata": {
    "id": "17cd5452"
   },
   "source": [
    "### Now you need to drop all the unnecessary columns - \n",
    "\n",
    "- 'business_code'\n",
    "- \"baseline_create_date\"\n",
    "- \"due_in_date\"\n",
    "- \"posting_date\"\n",
    "- \"name_customer\"\n",
    "- \"clear_date\"\n",
    "- \"cust_payment_terms\"\n",
    "- 'day_of_cleardate'\n",
    "- \"month_of_cleardate\"\n",
    "- \"year_of_cleardate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef54ea",
   "metadata": {
    "id": "d7c82076"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d4a9838",
   "metadata": {
    "id": "Q_NCr9IPweVq"
   },
   "source": [
    "### Check the information of the \"nulldata\" dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70195ce7",
   "metadata": {
    "id": "4e7ffee0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f081ed91",
   "metadata": {
    "id": "-XvjhWqmwi-C"
   },
   "source": [
    "### Compare \"nulldata\" with the \"X_test\" dataframe \n",
    "\n",
    "- use info() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280125da",
   "metadata": {
    "id": "02f4b62d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3883eb8",
   "metadata": {
    "id": "Us3ey-9zwqjq"
   },
   "source": [
    "### You must have noticed that there is a mismatch in the column sequence while compairing the dataframes\n",
    "\n",
    "- Note - In order to fed into the machine learning model, you need to edit the sequence of \"nulldata\", similar to the \"X_test\" dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645ecf7",
   "metadata": {
    "id": "vduVNt1kxPW-"
   },
   "source": [
    "- Display all the columns of the X_test dataframe \n",
    "- Display all the columns of the Nulldata dataframe \n",
    "- Store the Nulldata with new sequence into a new dataframe \n",
    "\n",
    "\n",
    "- Note - The code is given below, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb03c2e",
   "metadata": {
    "id": "6729353e"
   },
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c029ea",
   "metadata": {
    "id": "47bd9c5e"
   },
   "outputs": [],
   "source": [
    "nulldata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f7cd2",
   "metadata": {
    "id": "aa5a2103"
   },
   "outputs": [],
   "source": [
    "nulldata2=nulldata[['cust_number', 'buisness_year', 'doc_id', 'converted_usd',\n",
    "       'business_code_enc', 'name_customer_enc', 'cust_payment_terms_enc',\n",
    "       'day_of_postingdate', 'month_of_postingdate', 'year_of_postingdate',\n",
    "       'day_of_createdate', 'month_of_createdate', 'year_of_createdate',\n",
    "       'day_of_due', 'month_of_due', 'year_of_due']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd8f244",
   "metadata": {
    "id": "1dc8b021"
   },
   "source": [
    "### Display the Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a9d47",
   "metadata": {
    "id": "2f39785a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c156bd1",
   "metadata": {
    "id": "27b88c5a"
   },
   "source": [
    "### Now you can pass this dataset into you final model and store it into \"final_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e0fd6",
   "metadata": {
    "id": "9e0b6388"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66aae971",
   "metadata": {
    "id": "9653d3c6"
   },
   "source": [
    "### you need to make the final_result as dataframe, with a column name \"avg_delay\"\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209445df",
   "metadata": {
    "id": "25ef814d"
   },
   "outputs": [],
   "source": [
    "final_result = pd.Series(final_result,name='avg_delay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da5ffc5",
   "metadata": {
    "id": "C86staIhyf2C"
   },
   "source": [
    "### Display the \"avg_delay\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3cb653",
   "metadata": {
    "id": "4fd46406"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1e4ca04",
   "metadata": {
    "id": "44f71a7e"
   },
   "source": [
    "### Now you need to merge this final_result dataframe with the BACKUP of \"nulldata\" Dataframe which we have created in earlier steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33a5c9",
   "metadata": {
    "id": "e8f0969d"
   },
   "outputs": [],
   "source": [
    "nulldata1.reset_index(drop=True,inplace=True)\n",
    "Final = nulldata1.merge(final_result , on = nulldata.index )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b61b5",
   "metadata": {
    "id": "G-hLtxXgy4GZ"
   },
   "source": [
    "### Display the \"Final\" dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779cc43",
   "metadata": {
    "id": "71fb4dc0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad377a9b",
   "metadata": {
    "id": "4sc27Uz-y-0O"
   },
   "source": [
    "### Check for the Number of Rows and Columns in your \"Final\" dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f4f19",
   "metadata": {
    "id": "5iUXOIhzy_HR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4f01519",
   "metadata": {
    "id": "48886d2c"
   },
   "source": [
    "### Now, you need to do convert the below fields back into date and time format \n",
    "\n",
    "- Convert \"due_in_date\" into datetime format\n",
    "- Convert \"avg_delay\" into datetime format\n",
    "- Create a new column \"clear_date\" and store the sum of \"due_in_date\" and \"avg_delay\"\n",
    "- display the new \"clear_date\" column\n",
    "- Note - Code is given below, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21826e0",
   "metadata": {
    "id": "243abc2d"
   },
   "outputs": [],
   "source": [
    "Final['clear_date'] = pd.to_datetime(Final['due_in_date']) + pd.to_timedelta(Final['avg_delay'], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de7aac",
   "metadata": {
    "id": "9QcX_fAjIkYR"
   },
   "source": [
    "### Display the \"clear_date\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c64ea",
   "metadata": {
    "id": "740e1486"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c638fe6e",
   "metadata": {
    "id": "MSkNLq6-z7rZ"
   },
   "source": [
    "### Convert the average delay into number of days format \n",
    "\n",
    "- Note - Formula = avg_delay//(24 * 3600)\n",
    "- Note - full code is given for this, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b290b5e",
   "metadata": {
    "id": "ce6b618a"
   },
   "outputs": [],
   "source": [
    "Final['avg_delay'] = Final.apply(lambda row: row.avg_delay//(24 * 3600), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb4a4a",
   "metadata": {
    "id": "wbBBZPjP0W7o"
   },
   "source": [
    "### Display the \"avg_delay\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6357635",
   "metadata": {
    "id": "a494982f",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02b79920",
   "metadata": {
    "id": "815d8811"
   },
   "source": [
    "### Now you need to convert average delay column into bucket\n",
    "\n",
    "- Need to perform binning \n",
    "- create a list of bins i.e. bins= [0,15,30,45,60,100]\n",
    "- create a list of labels i.e. labels = ['0-15','16-30','31-45','46-60','Greatar than 60']\n",
    "- perform binning by using cut() function from \"Final\" dataframe\n",
    "\n",
    "\n",
    "- Please fill up the first two rows of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390a43c",
   "metadata": {
    "id": "c797e4b5"
   },
   "outputs": [],
   "source": [
    "\n",
    "bins= ___________________\n",
    "labels =__________________________\n",
    "Final['Aging Bucket'] = pd.cut(Final['avg_delay'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560418d3",
   "metadata": {
    "id": "1c35725f"
   },
   "source": [
    "### Now you need to drop \"key_0\" and \"avg_delay\" columns from the \"Final\" Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956c926",
   "metadata": {
    "id": "b31bc6a3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a337bee",
   "metadata": {
    "id": "Ui-tyIvU0-5u"
   },
   "source": [
    "### Display the count of each categoty of new \"Aging Bucket\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87833eff",
   "metadata": {
    "id": "a6e16218"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac347550",
   "metadata": {
    "id": "kgYegy551GKJ"
   },
   "source": [
    "### Display your final dataset with aging buckets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74860c89",
   "metadata": {
    "id": "c4bc87ec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e8dbcd9",
   "metadata": {
    "id": "Ji7AoDCB1L_x"
   },
   "source": [
    "### Store this dataframe into the .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed63120",
   "metadata": {
    "id": "727d0b8d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49c1ce2b",
   "metadata": {
    "id": "FK0fabl61SkC"
   },
   "source": [
    "# END OF THE PROJECT"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "62633a84"
   ],
   "name": "Payment date prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
